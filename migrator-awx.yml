## This modified version of the playbook expects a variable "source_vm_name" to be
## provided. In turn, it will fetch info on that VM, and the host it currently
## resides on, to dynamically populate the inventory groups. Although this was
## intended for use in self-service migrations in AWX, it could also be useful to
## further simplify the migration process when running manually.

- name: Collect VM info from survey
  hosts: localhost
  gather_facts: false

  vars_prompt:
    - name: source_vm_name
      prompt: What's the name of the VM in RHV?
      private: no

  tasks:
    - name: Collect VM info from RHV
      block:
        - name: Obtain SSO token using username/password credentials
          ovirt_auth:
            url: "{{ rhv_endpoint }}"
            username: "{{ rhv_username }}@{{ rhv_domain }}"
            password: "{{ rhv_password }}"
            insecure: true
          delegate_to: localhost

        - ovirt.ovirt.ovirt_vm_info:
            auth: "{{ ovirt_auth }}"
            pattern: "{{ source_vm_name }} and Status = up"
            follows:
              - disk_attachments.disk
              - nics.vnic_profile.network
          register: preload_rhv_vm

      always:
        - name: Always revoke the SSO token
          ovirt_auth:
            state: absent
            ovirt_auth: "{{ ovirt_auth }}"
          delegate_to: localhost

    - name: Fail if no VMs found
      ansible.builtin.fail:
        msg: >
          'No VMs were found matching the query. This could mean that you made a typo
          when entering the hostname, the VM was already migrated, or that it was powered
          off for other reason. Please make sure the name was entered correctly, and that
          the target VM is powered up.'
      when: preload_rhv_vm.ovirt_vms | length == 0

    - name: Fail if more than 1 VM is found
      ansible.builtin.fail:
        msg: >
          'More than 1 VM was returned from the search query. Please make sure the provided
          hostname is specific to a single VM'
      when: preload_rhv_vm.ovirt_vms | length > 1

    - name: Notify pending changes
      debug:
        msg: >
          'This VM is marked as having a "Next Run Configuration", 
          likely due to a prior CPU/RAM adjustment. 
          We'll attampt to handle this ourselves by cleanly powering down the machine,
          but if that fails, you may need to manually reboot your VM, and re-run this tool.'
      when: preload_rhv_vm.ovirt_vms[0].next_run_configuration_exists | bool

    - name: Add discovered VM to inventory
      ansible.builtin.add_host:
        name: "{{ source_vm_name }}"
        groups:
          - vmsToMigrate
        rhv_data: preload_rhv_vm.ovirt_vms[0]

- name: Mount vmware_migration volume
  hosts: rhvhost
  become: true
  gather_facts: true

  tasks:
    - name: Create a directory for the vmware_migration volume
      ansible.builtin.file:
        path: /mnt/vmware_migration
        state: directory
        mode: '0755'

    - name: Mount vmware_migration volume locally to RHV host
      mount:
        src: "{{ nfs_mount_path }}"
        path: /mnt/vmware_migration
        boot: no
        state: mounted
        fstype: nfs
        opts: vers=3

- name: Prepare source VM for migration
  hosts: vmsToMigrate:!no_guest_preparation
  become: true
  gather_facts: true

  tasks:
    - name: Run guest-specific migration preparation
      ansible.builtin.include_role:
        name: guest_preparation

- name: Build skeleton VM on vSphere
  hosts: vmsToMigrate
  gather_facts: false
  connection: local

  tasks:
    - name: Collect VM specifications from RHV
      block:
        - name: Obtain SSO token with using username/password credentials
          ovirt_auth:
            url: "{{ rhv_endpoint }}"
            username: "{{ rhv_username }}@{{ rhv_domain }}"
            password: "{{ rhv_password }}"
            insecure: true

        - ovirt.ovirt.ovirt_vm_info:
            auth: "{{ ovirt_auth }}"
            pattern: "{{ inventory_hostname }}"
            follows:
              - disk_attachments.disk
              - nics.vnic_profile.network
          register: rhv_vm
        - set_fact: vm_name="{{rhv_vm.ovirt_vms[0].name}}"

## All this, just to get the datacenter ID, which should've just been included in the VM response
        - ovirt.ovirt.ovirt_cluster_info:
            auth: "{{ ovirt_auth }}"
          register: rhv_clusters
        - set_fact: rhv_vm_datacenter_id="{{item.data_center.id}}"
          loop: "{{ rhv_clusters.ovirt_clusters }}"
          loop_control:
            label: "{{item.name}}"
          when: item.id == rhv_vm.ovirt_vms[0].cluster.id

      always:
        - name: Always revoke the SSO token
          ovirt_auth:
            state: absent
            ovirt_auth: "{{ ovirt_auth }}"

    - name: Create target VM in vCenter
      community.vmware.vmware_guest:
        hostname: "{{ vcenter_endpoint }}"
        username: "{{ vcenter_username }}"
        password: "{{ vcenter_password }}"
        validate_certs: false
        folder: /Migrated Virtual Machines
        datastore: "{{ vcenter_datastore }}"
        datacenter: "{{ vcenter_datacenter }}"
        cluster: "{{ vcenter_cluster }}"
        name: "{{ rhv_vm.ovirt_vms[0].name }}"
        guest_id: centos64Guest
        hardware:
          boot_firmware: bios
          hotadd_cpu: yes
          hotadd_memory: yes
          # yOu HaVe A pRoBlEm WiTh PrEcIsIoN?
          memory_mb: "{{ (rhv_vm.ovirt_vms[0].memory / 1024 / 1024) | int }}"
          num_cpus: "{{ rhv_vm.ovirt_vms[0].cpu.topology.sockets }}"
          scsi: paravirtual
      register: vmware_vm
    - set_fact: vmware_vm_info="{{vmware_vm.instance}}"
      
    - name: Add network adapter to VM
      community.vmware.vmware_guest_network:
        hostname: "{{ vcenter_endpoint }}"
        username: "{{ vcenter_username }}"
        password: "{{ vcenter_password }}"
        validate_certs: false
        datacenter: "{{ vcenter_datacenter }}"
        moid: "{{ vmware_vm_info.moid }}"
        switch: "{{ vcenter_datacenter }}-dvswitch"
        start_connected: yes
        vlan_id: "{{ adapter.vnic_profile.network.vlan.id }}"
      loop: "{{ rhv_vm.ovirt_vms[0].nics }}"
      loop_control:
        label: "{{adapter.name}}"
        index_var: loop_index
        loop_var: adapter

- name: The Main Event
  hosts: vmsToMigrate
  gather_facts: false
  strategy: free

  tasks:
    - name: Start Migration
      block:
      - name: Annotate the source VM
        ovirt.ovirt.ovirt_vm:
          auth:
            url: "{{ rhv_endpoint }}"
            username: "{{ rhv_username }}@{{ rhv_domain }}"
            password: "{{ rhv_password }}"
            insecure: true
          comment: "Pending vSphere Migration"
          name: "{{ vm_name }}"
        delegate_to: localhost
      - name: Stop the source VM
        ovirt.ovirt.ovirt_vm:
          auth:
            url: "{{ rhv_endpoint }}"
            username: "{{ rhv_username }}@{{ rhv_domain }}"
            password: "{{ rhv_password }}"
            insecure: true
          state: stopped
          name: "{{ vm_name }}"
        delegate_to: localhost

      - name: Convert and Attach disks to target VM
        include_tasks: fragments/convert_and_import_disk.yml
        loop: "{{rhv_vm.ovirt_vms[0].disk_attachments | sort(attribute='disk.alias')}}"
        loop_control:
          label: "{{item.id}}"
          index_var: loop_index

      - name: Power up the target VM
        community.vmware.vmware_guest:
          hostname: "{{ vcenter_endpoint }}"
          username: "{{ vcenter_username }}"
          password: "{{ vcenter_password }}"
          validate_certs: false
          datacenter: "{{ vcenter_datacenter }}"
          name: "{{ vmware_vm_info.hw_name }}"
          state: poweredon
          wait_for_ip_address: yes
        delegate_to: localhost

      - name: Annotate the source VM
        ovirt.ovirt.ovirt_vm:
          auth:
            url: "{{ rhv_endpoint }}"
            username: "{{ rhv_username }}@{{ rhv_domain }}"
            password: "{{ rhv_password }}"
            insecure: true
          comment: "Migrated to vSphere"
          name: "{{ vm_name }}"
        delegate_to: localhost
      rescue:
        - name: Start source VM due to migration failure
          ovirt.ovirt.ovirt_vm:
            auth:
              url: "{{ rhv_endpoint }}"
              username: "{{ rhv_username }}@{{ rhv_domain }}"
              password: "{{ rhv_password }}"
              insecure: true
            state: running
            name: "{{ vm_name }}"
          delegate_to: localhost
        - name: Annotate the source VM
          ovirt.ovirt.ovirt_vm:
            auth:
              url: "{{ rhv_endpoint }}"
              username: "{{ rhv_username }}@{{ rhv_domain }}"
              password: "{{ rhv_password }}"
              insecure: true
            comment: "Migration to vSphere failed"
            name: "{{ vm_name }}"
          delegate_to: localhost
        - ansible.builtin.fail:
            msg: "Something went wrong while attempting to migrate {{ vm_name }}, the source VM has been powered back up."
      always:
        - debug:
            msg: "We would've removed the SSO token here"